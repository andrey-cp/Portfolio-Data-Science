{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f0226c2",
   "metadata": {},
   "source": [
    "# 1. Introdução\n",
    "\n",
    "Nosso trabalho aqui consiste em criar um modelo para prever preços de diamantes a partir de suas características.\n",
    "\n",
    "Fonte: https://www.kaggle.com/datasets/nancyalaswad90/diamonds-prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6a163d",
   "metadata": {},
   "source": [
    "# 2. Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d1a91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para tratar os dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Pré-processamento\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer # pipeline com colunas de tipos diferentes\n",
    "from sklearn.impute import SimpleImputer # missing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder # escala das features / tratar categóricas numéricas\n",
    "from category_encoders import TargetEncoder, OneHotEncoder # tratamento de categóricas\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif, f_regression # selecao de features\n",
    "\n",
    "# Modelagem\n",
    "import lightgbm as lgb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bf812c",
   "metadata": {},
   "source": [
    "### Importando o Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dda52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds_data = pd.read_csv('Diamonds Prices2022.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7ac152",
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6139869",
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67069dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb6e195",
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds_data.isna().sum() # mean para ver a taxa de missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0ec797",
   "metadata": {},
   "source": [
    "Digamos que a gente queira excluir linhas com mais de 30% de missing. O que fazer?\n",
    "```python\n",
    "diamonds_data = (diamonds_data.isna().mean() <= 0.3).index\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c8be57",
   "metadata": {},
   "source": [
    "# 3. Análise Exploratória"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90aa3206",
   "metadata": {},
   "source": [
    "Dessa vez, não vamos fazer análise exploratória. Vamos olhar mais sob a perspectiva de um projeto automatizado onde não é possível ficar olhando as features uma a uma. Além disso, nem sempre vamos conseguir confiar 100% na EDA. Então é importante conhecer técnicas de feature selection e não achar que a EDA é a resposta final."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07eb2703",
   "metadata": {},
   "source": [
    "# 4. Modelo preditivo de preço"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffd7540",
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7544b066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos começar removendo a 'Unnamed: 0' que não vai nos servir de nada.\n",
    "diamonds_data.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22df8f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c397788c",
   "metadata": {},
   "source": [
    "A descrição no Kaggle nos informou que as variáveis cut, color e clarity são categóricas ordinais. Então a ordem delas importa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24657d0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diamonds_data['cut'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6edda7f",
   "metadata": {},
   "source": [
    " Fair ➡ Good ➡ Very Good ➡ Premium ➡ Ideal (Do pior para o melhor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3c89fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds_data['color'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a600b6fb",
   "metadata": {},
   "source": [
    "J ➡ I ➡ H ➡ G ➡ F ➡ E ➡ D (Do pior para o melhor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf4e545",
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds_data['clarity'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c5302c",
   "metadata": {},
   "source": [
    " I1 ➡ SI2 ➡ SI1 ➡ VS2 ➡ VS1 ➡ VVS2 ➡ VVS1 ➡ IF (Do pior para o melhor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3180d3a",
   "metadata": {},
   "source": [
    "Removendo duplicatas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca1b29d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diamonds_data[diamonds_data.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564afca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds_data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c57c81a",
   "metadata": {},
   "source": [
    "Agora vamos verificar a presença de outliers. No caso de diamantes, é esperado que tenhamos uma variação considerável nos preços. Então vamos ver qual a porcentagem de outliers em cada coluna. Se a quantidade for pequena, podemos considerar que podem ser dados legítimos e/ou o impacto no modelo não deve ser significativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ab5ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando quais são as colunas numéricas. Vamos aproveitar pra criar a lista de categóricas também.\n",
    "\n",
    "numerical_columns = diamonds_data.select_dtypes(include=\"number\").columns.to_list()\n",
    "categorical_columns = diamonds_data.select_dtypes(exclude=\"number\").columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcbfcf3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "numerical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b843168",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e157870",
   "metadata": {},
   "source": [
    "Caso fosse necessário, uma forma de criar dataframes de features numéricas e categóricas seria:\n",
    "```python\n",
    "cols = diamonds_data.dtypes.reset_index().rename(columns={'index': 'coluna', 0: 'tipo'})\n",
    "num_cols = cols[cols['tipo'] != object]\n",
    "categ_cols = cols[cols['tipo'] == object]\n",
    "```\n",
    "Dessa forma teríamos um dataframe com as colunas e seus tipos (int, float, object, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29544e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detectando outliers\n",
    "\n",
    "nomes_colunas = []\n",
    "qtt_outliers = []\n",
    "\n",
    "for i in numerical_columns:\n",
    "    \n",
    "    contador = 0\n",
    "    \n",
    "    q1 = np.quantile(diamonds_data[i], 0.25) # primeiro quartil\n",
    "    q3 = np.quantile(diamonds_data[i], 0.75) # terceiro quartil\n",
    "    li = q1 - 1.5*(q3-q1) # limite inferior\n",
    "    ls = q3 + 1.5*(q3-q1) # limite superior\n",
    "    \n",
    "    for j in diamonds_data.index:\n",
    "        if li <= diamonds_data[i][j] <= ls:\n",
    "            pass\n",
    "        else:\n",
    "            contador += 1\n",
    "    \n",
    "    perc_outliers = (contador / diamonds_data[i].count())*100 # porcentagem da quantidade de outliers nessa coluna\n",
    "    \n",
    "    nomes_colunas.append(i)\n",
    "    qtt_outliers.append(perc_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aeead73",
   "metadata": {},
   "outputs": [],
   "source": [
    "nomes_colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b75cec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outliers = pd.DataFrame()\n",
    "outliers['coluna'] = nomes_colunas\n",
    "outliers['perc_outliers'] = qtt_outliers\n",
    "outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bb7d2f",
   "metadata": {},
   "source": [
    "Se eu quisesse filtrar as colunas com mais de X% de outliers, por exemplo, poderia fazer assim:\n",
    "```python\n",
    "outliers[outliers['perc_outliers'] > X]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe8d4fc",
   "metadata": {},
   "source": [
    "Como pudemos visualizar, a quantidade de outliers é bem pequena. A coluna Price é a que tem a maior quantidade de outliers com 6,5%. Então, nesse caso, não vamos optar pela remoção desses outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae66e02",
   "metadata": {},
   "source": [
    "Agora vamos remover a coluna price da nossa lista de colunas numéricas, afinal, ele é o nosso target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358b424e",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = [feature for feature in numerical_columns if feature != 'price']\n",
    "numerical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5c9968",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'price'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c0fa57",
   "metadata": {},
   "source": [
    "Antes de fazer a divisão, vamos fazer um mapeamento nas colunas categóricas. Como foi dito anteriormente, a ordem delas importa, então vamos fazer um Ordinal Encoder manualmente. O ideal é sempre fazer o pré-processamento após o split, porém, como nesse caso não estamos usando informações da coluna inteira para preencher um missing, por exemplo, não teremos risco de data leakage. Portanto, podemos fazer esse encoding antes da divisão (e nesse caso, é até mais prático)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f8e4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds_data['cut'] = diamonds_data['cut'].map({'Fair':0, 'Good':1, 'Very Good':2, 'Premium':3, 'Ideal':4})\n",
    "diamonds_data['color'] = diamonds_data['color'].map({'J':0, 'I':1, 'H':2, 'G':3, 'F':4, 'E':5, 'D':6})\n",
    "diamonds_data['clarity'] = diamonds_data['clarity'].map({'I1':0, 'SI2':1, 'SI1':2, 'VS2':3, 'VS1':4, 'VVS2':5, 'VVS1':6, 'IF':7})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b76754c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diamonds_data[numerical_columns + categorical_columns]\n",
    "y = diamonds_data[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107d5d53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c1d877",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lgb_model = lgb.LGBMRegressor()\n",
    "\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy='median')),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "# Obs.: Nesse nosso caso, as colunas categóricas já foram transformadas em numéricas. Vamos manter o nome\n",
    "# assim por uma questão de organização, mas na prática o nosso categorical_transformer vai funcionar assim\n",
    "# como o numerical_transformer.\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy='most_frequent'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numerical_transformer, numerical_columns),\n",
    "    ('cat', categorical_transformer, categorical_columns)\n",
    "]\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_selection', SelectKBest(score_func=f_regression, k='all')), \n",
    "    ('model', lgb_model)\n",
    "])\n",
    "\n",
    "# Treina o modelo\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54838295",
   "metadata": {},
   "source": [
    "Vamos enfim realizar a nossa predição e verificar o desempenho do modelo com algumas métricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8e490d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error (MSE) test:  {mse:.4f}')\n",
    "print(f'Root Mean Squared Error (RMSE) test:  {rmse:.4f}')\n",
    "print(f'Mean Absolute Error (MAE) test:  {mae:.4f}')\n",
    "print(f'R-squared (R2) test:  {r2:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39da2541",
   "metadata": {},
   "source": [
    "Vamos comparar as mesmas métricas do modelo fazendo predições com os dados de treino agora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52a11f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_train = pipeline.predict(X_train)\n",
    "mse = mean_squared_error(y_train, y_pred_train)\n",
    "mae = mean_absolute_error(y_train, y_pred_train)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_train, y_pred_train)\n",
    "\n",
    "print(f'Mean Squared Error (MSE) train:  {mse:.4f}')\n",
    "print(f'Root Mean Squared Error (RMSE) train:  {rmse:.4f}')\n",
    "print(f'Mean Absolute Error (MAE) train:  {mae:.4f}')\n",
    "print(f'R-squared (R2) train:  {r2:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84ea7d4",
   "metadata": {},
   "source": [
    "Agora uma comparação direta de 50 valores que o algoritmo preveu com os dados de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84318577",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_test_list = y_test.to_list()\n",
    "for x in range(0, 50):\n",
    "    print(f'y_test: {y_test_list[x]} / y_pred: {y_pred[x]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c201e7aa",
   "metadata": {},
   "source": [
    "Visualizando graficamente a comparação de y_test e y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1827448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f028b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar um DataFrame com y_test e y_pred\n",
    "df = pd.DataFrame({'y_test': y_test, 'y_pred': y_pred})\n",
    "\n",
    "# Plotar a relação entre as duas colunas\n",
    "sns.relplot(data=df, x='y_test', y='y_pred')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3aa9b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
