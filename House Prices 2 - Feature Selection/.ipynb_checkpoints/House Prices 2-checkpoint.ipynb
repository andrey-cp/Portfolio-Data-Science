{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8271a75b",
   "metadata": {},
   "source": [
    "# House Prices 2\n",
    "Competição do Kaggle sobre a previsão de preço das casa na cidade de Ames, Iowa (Estados Unidos).\n",
    "Essa é uma segunda resolução deste problema presente aqui no meu portfólio. A intenção aqui é utilizar pipelines e técnicas de feature selection para a otimização dos modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a6c860",
   "metadata": {},
   "source": [
    "# Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d772d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para tratar os dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Pré-processamento\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer # pipeline com colunas de tipos diferentes\n",
    "from sklearn.impute import SimpleImputer # missing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder # escala das features / tratar categóricas numéricas\n",
    "from category_encoders import TargetEncoder, OneHotEncoder # tratamento de categóricas\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif, f_regression # selecao de features\n",
    "\n",
    "# Modelagem\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Métricas de avaliação\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63f658f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando o dataset de treino\n",
    "houses_train = pd.read_csv('train.csv')\n",
    "houses_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154336ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40761a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1ee0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18237a03",
   "metadata": {},
   "source": [
    "# Explorando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26e7d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos verificar a quantidade de valores vazios\n",
    "houses_train.isnull().sum().sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621623d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Em porcentagem\n",
    "(houses_train.isnull().sum()/houses_train.shape[0]).sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5766c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos eliminar as colunas com mais de 20% de valores vazios\n",
    "eliminar = houses_train.columns[(houses_train.isnull().sum() / houses_train.shape[0]) > 0.2]\n",
    "eliminar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6dd1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminando essas colunas tanto do dataset de treino quanto do dataset de teste\n",
    "houses_train.drop(eliminar, axis=1, inplace=True)\n",
    "houses_test.drop(eliminar, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2982e337",
   "metadata": {},
   "outputs": [],
   "source": [
    "(houses_train.isnull().sum()/houses_train.shape[0]).sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e9d1e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "houses_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f285986d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos eliminar também o Id, já que essa coluna é irrelevante\n",
    "houses_train.drop('Id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd2d2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando se há duplicatas nos dados de treino\n",
    "houses_train.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81e0790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando se há duplicatas nos dados de teste\n",
    "houses_test.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f8b6f4",
   "metadata": {},
   "source": [
    "Até o momento, removemos algumas colunas que possuíam uma porcentagem alta de valores nulos e também confirmamos que não há duplicatas em nosso conjunto de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea73ebb",
   "metadata": {},
   "source": [
    "# Verificando outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67187ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando quais são as colunas numéricas. Vamos aproveitar pra criar a lista de categóricas também.\n",
    "\n",
    "numerical_columns = houses_train.select_dtypes(include=\"number\").columns.to_list()\n",
    "categorical_columns = houses_train.select_dtypes(exclude=\"number\").columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0790da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(numerical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6740bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c5ad11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detectando outliers\n",
    "\n",
    "nomes_colunas = []\n",
    "qtt_outliers = []\n",
    "\n",
    "for i in numerical_columns:\n",
    "    \n",
    "    contador = 0\n",
    "    \n",
    "    q1 = np.quantile(houses_train[i], 0.25) # primeiro quartil\n",
    "    q3 = np.quantile(houses_train[i], 0.75) # terceiro quartil\n",
    "    li = q1 - 1.5*(q3-q1) # limite inferior\n",
    "    ls = q3 + 1.5*(q3-q1) # limite superior\n",
    "    \n",
    "    for j in houses_train.index:\n",
    "        if li <= houses_train[i][j] <= ls:\n",
    "            pass\n",
    "        else:\n",
    "            contador += 1\n",
    "    \n",
    "    perc_outliers = (contador / houses_train[i].count())*100 # porcentagem da quantidade de outliers nessa coluna\n",
    "    \n",
    "    nomes_colunas.append(i)\n",
    "    qtt_outliers.append(perc_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13289a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nomes_colunas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f04a49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = pd.DataFrame()\n",
    "outliers['coluna'] = nomes_colunas\n",
    "outliers['perc_outliers'] = qtt_outliers\n",
    "outliers.sort_values(by='perc_outliers', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bae608d",
   "metadata": {},
   "source": [
    "Há três colunas com uma porcentagem muito alta de outliers. Vamos dar uma olhada em seus valores e tentar descobrir se eles realmente fazem sentido ou devemos excluí-las."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d22f10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_alto = outliers[outliers['perc_outliers'] > 90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a11576",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_alto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676cdfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in outlier_alto['coluna']:\n",
    "    print('Coluna: ' + column)\n",
    "    print(f'Média: {houses_train[column].mean()}')\n",
    "    print(f'Mediana: {houses_train[column].median()}')\n",
    "    print(f'Min: {houses_train[column].min()}')\n",
    "    print(f'Max: {houses_train[column].max()}')\n",
    "    print('---------------------------------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386d833b",
   "metadata": {},
   "source": [
    "A coluna 'LotFrontage' se refere à medida de pés lineares de rua conectada à casa. A coluna 'MasVnrArea' se refere à área folheada de alvenaria em pés quadrados. A coluna 'GarageYrBlt' se refere ao ano em que a garagem foi construída. \n",
    "\n",
    "Olhando essas medias e a descrição de cada coluna, é possível notar que faz sentido os intervalos desses valores variarem de tal forma. Vamos então considerar que esses outliers de fato são valores reais do nosso conjunto de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c70294",
   "metadata": {},
   "source": [
    "# Tratando variáveis categóricas ordinais\n",
    "\n",
    "* Verificando a descrição das variáveis no Kaggle, podemos ver quais categóricas são ordinais, então vamos tratá-las agora. Nesse caso, como estamos apenas substituindo os seus valores por um número correspondente sem usar nenhuma informação de outra linha ou coluna, não teremos o risco de data leakage. \n",
    "* Obs.: Estamos desconsiderando as colunas que já excluímos anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd1b18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "categ_ordinais_na_to_ex = ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond',\n",
    "                  'HeatingQC', 'KitchenQual', 'GarageQual',\n",
    "                  'GarageCond',]\n",
    "\n",
    "for column in categ_ordinais_na_to_ex:\n",
    "    houses_train[column] = houses_train[column].map({'Po':2, 'Fa':3, 'TA':5, 'Gd':7, 'Ex': 9})\n",
    "    houses_train[column].fillna(0, inplace=True)\n",
    "    houses_test[column] = houses_test[column].map({'Po':2, 'Fa':3, 'TA':5, 'Gd':7, 'Ex': 9})\n",
    "    houses_test[column].fillna(0, inplace=True)\n",
    "\n",
    "houses_train['CentralAir'] = houses_train['CentralAir'].map({'N' :0, 'Y':1})\n",
    "houses_test['CentralAir'] = houses_test['CentralAir'].map({'N' :0, 'Y':1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8b803d",
   "metadata": {},
   "source": [
    "# Criando os modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9305a281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos selecionar X e y\n",
    "X = houses_train.drop('SalePrice', axis=1)\n",
    "y = houses_train.SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de8dd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando entre treino e validação. Os dados de teste estão no dataset houses_test\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4552cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_val shape: {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c5f609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos remover a coluna SalePrice da nossa lista de colunas numéricas, já que ela é o nosso target\n",
    "numerical_columns = [feature for feature in numerical_columns if feature != 'SalePrice']\n",
    "print(numerical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4f3af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instancia os modelos\n",
    "lgb_model = lgb.LGBMRegressor()\n",
    "lr_model = LinearRegression()\n",
    "rf_model =  RandomForestClassifier()\n",
    "knn_model = KNeighborsRegressor(n_neighbors=5)\n",
    "\n",
    "# Preparando os pipelines\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', TargetEncoder())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numerical_transformer, numerical_columns),\n",
    "    ('cat', categorical_transformer, categorical_columns)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c3dbec",
   "metadata": {},
   "source": [
    "# Testando o LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f895a4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('lgbm', lgb_model)\n",
    "])\n",
    "\n",
    "# Treina o modelo\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Cria predições nos dados de validação para avaliar o desempenho\n",
    "y_pred = pipe.predict(X_val)\n",
    "\n",
    "# Avalia o modelo\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error (MSE) test:  {mse:.4f}')\n",
    "print(f'Root Mean Squared Error (RMSE) test:  {rmse:.4f}')\n",
    "print(f'Mean Absolute Error (MAE) test:  {mae:.4f}')\n",
    "print(f'R-squared (R2) test:  {r2:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351e63c7",
   "metadata": {},
   "source": [
    "# Testando a Regressão Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9062ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('linear_regression', lr_model)\n",
    "])\n",
    "\n",
    "# Treina o modelo\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Cria predições nos dados de validação para avaliar o desempenho\n",
    "y_pred = pipe.predict(X_val)\n",
    "\n",
    "# Avalia o modelo\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error (MSE) test:  {mse:.4f}')\n",
    "print(f'Root Mean Squared Error (RMSE) test:  {rmse:.4f}')\n",
    "print(f'Mean Absolute Error (MAE) test:  {mae:.4f}')\n",
    "print(f'R-squared (R2) test:  {r2:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0b07e0",
   "metadata": {},
   "source": [
    "# Testando a Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02909280",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('random_forest', rf_model)\n",
    "])\n",
    "\n",
    "# Treina o modelo\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Cria predições nos dados de validação para avaliar o desempenho\n",
    "y_pred = pipe.predict(X_val)\n",
    "\n",
    "# Avalia o modelo\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error (MSE) test:  {mse:.4f}')\n",
    "print(f'Root Mean Squared Error (RMSE) test:  {rmse:.4f}')\n",
    "print(f'Mean Absolute Error (MAE) test:  {mae:.4f}')\n",
    "print(f'R-squared (R2) test:  {r2:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43b6343",
   "metadata": {},
   "source": [
    "# Testando o KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b189e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('KNN', knn_model)\n",
    "])\n",
    "\n",
    "# Treina o modelo\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Cria predições nos dados de validação para avaliar o desempenho\n",
    "y_pred = pipe.predict(X_val)\n",
    "\n",
    "# Avalia o modelo\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error (MSE) test:  {mse:.4f}')\n",
    "print(f'Root Mean Squared Error (RMSE) test:  {rmse:.4f}')\n",
    "print(f'Mean Absolute Error (MAE) test:  {mae:.4f}')\n",
    "print(f'R-squared (R2) test:  {r2:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2480de0a",
   "metadata": {},
   "source": [
    "Como pudemos ver, o LGBM foi o modelo que obteve o melhor resultado. Então vamos fazer alguns testes de feature selection com ele e ver se conseguimos melhorar ainda mais as métricas de avaliação."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a2ee58",
   "metadata": {},
   "source": [
    "# Exclusão de features constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9a431e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.selection import DropConstantFeatures\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('drop_constant_features', DropConstantFeatures()),\n",
    "    ('lgbm', lgb_model)\n",
    "])\n",
    "\n",
    "# Treina o modelo\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Cria predições nos dados de validação para avaliar o desempenho\n",
    "y_pred = pipe.predict(X_val)\n",
    "\n",
    "# Avalia o modelo\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error (MSE) test:  {mse:.4f}')\n",
    "print(f'Root Mean Squared Error (RMSE) test:  {rmse:.4f}')\n",
    "print(f'Mean Absolute Error (MAE) test:  {mae:.4f}')\n",
    "print(f'R-squared (R2) test:  {r2:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edfcd5d",
   "metadata": {},
   "source": [
    "Pelo que pudemos ver, não houve nenhuma mudança nas métricas. Vamos tentar outro método então."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2635b8",
   "metadata": {},
   "source": [
    "# Exclusão de features correlacionadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f46d3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.selection import DropCorrelatedFeatures\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('drop_correlated_features', DropCorrelatedFeatures()),\n",
    "    ('lgbm', lgb_model)\n",
    "])\n",
    "\n",
    "# Treina o modelo\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Cria predições nos dados de validação para avaliar o desempenho\n",
    "y_pred = pipe.predict(X_val)\n",
    "\n",
    "# Avalia o modelo\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error (MSE) test:  {mse:.4f}')\n",
    "print(f'Root Mean Squared Error (RMSE) test:  {rmse:.4f}')\n",
    "print(f'Mean Absolute Error (MAE) test:  {mae:.4f}')\n",
    "print(f'R-squared (R2) test:  {r2:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360b4fa7",
   "metadata": {},
   "source": [
    "Também não houve nenhuma mudança significativa. Vamos seguir tentando."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8582f6f",
   "metadata": {},
   "source": [
    "# Exclusão de features correlacionadas com SmartCorrelatedSelection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c287db3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.selection import SmartCorrelatedSelection\n",
    "\n",
    "scs = SmartCorrelatedSelection(\n",
    "    method='spearman',\n",
    "    threshold=0.8,\n",
    "    missing_values='raise',\n",
    "    selection_method='variance'\n",
    ")\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('smart_correlated_selection', scs),\n",
    "    ('lgbm', lgb_model)\n",
    "])\n",
    "\n",
    "# Treina o modelo\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Cria predições nos dados de validação para avaliar o desempenho\n",
    "y_pred = pipe.predict(X_val)\n",
    "\n",
    "# Avalia o modelo\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error (MSE) test:  {mse:.4f}')\n",
    "print(f'Root Mean Squared Error (RMSE) test:  {rmse:.4f}')\n",
    "print(f'Mean Absolute Error (MAE) test:  {mae:.4f}')\n",
    "print(f'R-squared (R2) test:  {r2:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c764ac",
   "metadata": {},
   "source": [
    "Também não houve uma grande mudança, mas podemos ver que o modelo teve uma pequena melhora.\n",
    "Há outras maneiras de fazer a seleção de features e melhorar nosso modelo. Mas por ora, vamos testar o desempenho nos dados de teste e ver como fica nossa pontuação no Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a741af21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.selection import SmartCorrelatedSelection\n",
    "\n",
    "scs = SmartCorrelatedSelection(\n",
    "    method='spearman',\n",
    "    threshold=0.8,\n",
    "    missing_values='raise',\n",
    "    selection_method='variance'\n",
    ")\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('smart_correlated_selection', scs),\n",
    "    ('lgbm', lgb_model)\n",
    "])\n",
    "\n",
    "# Treina o modelo\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Cria predições nos dados de teste\n",
    "y_pred = pipe.predict(houses_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4568b29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea5e657",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
